# OCR Accelerator - `llm.py`

## Overview

The `llm.py` module handles interactions with the Large Language Model (LLM) for generating AI conclusions. It uses the Google Generative AI library to process the OCR results and generate structured responses based on specific instructions. This module is crucial for enhancing the OCR results with AI-driven insights and conclusions.

## Features

- **LLM Configuration**: Sets up the API key for the LLM.
- **Response Restructuring**: Generates structured responses using the LLM based on specific instructions.
- **Error Handling**: Provides robust error handling for API interactions and response generation.

## Key Components

### `restructure_response` Function

The `restructure_response` function generates a structured response using the LLM.

#### Parameters

- **`result`**: The OCR result that needs to be processed.
- **`llm_instruction`**: Specific instructions for the LLM to process the OCR result.

#### Returns

- **`str`**: The structured response generated by the LLM.

```python
import os
import logging
import google.generativeai as genai
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
load_dotenv()
logger.info("Setting up Gemini API key")

# os.environ["GEMINI_API_KEY"] = os.getenv("GEMINI_API_KEY")
if not os.environ["GEMINI_API_KEY"]:
    logger.warning("Gemini API key is empty")
else:
    logger.info("Gemini API key set successfully")

regen_document_types = ["medical_records", "log_notes"]
regen_model_types = ["llama_parse_gemini_pro", "llama_parse_gemini_flash", "llama_parse_gpt4_mini"]

def restructure_response(result, llm_instruction):
    logger.info("Starting restructure_response function")

    try:
        genai.configure(api_key=os.environ["GEMINI_API_KEY"])
        logger.info("Gemini API configured")
    except Exception as e:
        logger.error(f"Error configuring Gemini API: {str(e)}")
        raise

    generation_config = {
        "temperature": 0.5,
        "top_p": 0.2,
        "top_k": 64,
        "max_output_tokens": 8192,
        "response_mime_type": "text/plain",
    }
    logger.info("Generation config set")

    try:
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config=generation_config,
            system_instruction=llm_instruction
        )
        logger.info("Generative model initialized")
    except Exception as e:
        logger.error(f"Error initializing generative model: {str(e)}")
        raise

    try:
        response = model.generate_content(result)
        logger.info("Message sent and response received")
        return response.text
    except Exception as e:
        logger.error(f"Error sending message or receiving response: {str(e)}")
        raise

logger.info("restructure_response function defined successfully")
```

### `regen_document_types` and `regen_model_types`

These lists define the document types and model types that require regeneration.

```python
regen_document_types = ["medical_records", "log_notes"]
regen_model_types = ["llama_parse_gemini_pro", "llama_parse_gemini_flash", "llama_parse_gpt4_mini"]
```

## Usage

The `llm.py` module is used to generate AI conclusions based on the OCR results. This module is integrated into the main application to enhance the OCR results with AI-driven insights.

### Example Usage

```python
from llm import restructure_response

# Example OCR result
ocr_result = "This is the OCR result text that needs to be processed."

# Example LLM instruction
llm_instruction = """Structure this log record with attention to:
CONTENT PRIORITIES:
- Temporal information (dates, times, durations, intervals)
- Entry identifiers and sequence numbers
- Names and identifiers of involved parties
- Categorical classifications
- Numerical data and measurements
- Action items and follow-ups
- Notes and observations
- References to other entries

STRUCTURAL REQUIREMENTS:
- Maintain strict chronological order
- Preserve entry relationships
- Group related information
- Identify entry hierarchies
- Link connected entries
- Maintain column structure
- Preserve entry boundaries

OUTPUT FORMAT:
- Structure as markdown tables
- Include metadata headers
- Use consistent date/time formatting
- Standardize abbreviations
- Preserve numerical precision
- Maintain list structures
- Clear entry separation"""

# Generate structured response
structured_response = restructure_response(ocr_result, llm_instruction)

# Print the structured response
print(structured_response)
```

## Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---